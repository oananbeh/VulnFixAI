{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWV: 3000 rows saved to /Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/LOWV.csv\n",
      "LOIS: 5000 rows saved to /Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/LOIS.csv\n",
      "ITV: 2000 rows saved to /Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/ITV.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# mapping of CWE ID to vulnerability categories\n",
    "\n",
    "# Define the mapping of CWE to vulnerability categories\n",
    "cwe_category_mapping = {\n",
    "    'CWE-23': 'LOWV',\n",
    "    'CWE-134': 'LOWV',\n",
    "    'CWE-470': 'LOWV',\n",
    "    'CWE-502': 'LOIS',\n",
    "    'CWE-113': 'LOIS',\n",
    "    'CWE-601': 'LOIS',\n",
    "    'CWE-78': 'LOIS',\n",
    "    'CWE-79': 'LOIS',\n",
    "    'CWE-918': 'ITV',\n",
    "    'CWE-319': 'ITV'\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store dataframes by category\n",
    "category_dfs = {\n",
    "    'LOWV': [],\n",
    "    'LOIS': [],\n",
    "    'ITV': []\n",
    "}\n",
    "# Path to the final dataset\n",
    "file_path = '/Users/obiedaananbeh/Desktop/Repo/VulDediction/DataSet/final_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Read the final dataset\n",
    "    final_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Map rows to categories based on the \"CWE ID\" column\n",
    "    for cwe_id, category in cwe_category_mapping.items():\n",
    "        # Filter rows matching the current CWE ID\n",
    "        filtered_df = final_df[final_df['CWE ID'] == cwe_id]\n",
    "        \n",
    "        if not filtered_df.empty:\n",
    "            # Add the filtered rows to the corresponding category\n",
    "            category_dfs[category].append(filtered_df)\n",
    "    \n",
    "    # Combine dataframes for each category\n",
    "    for category in category_dfs:\n",
    "        if category_dfs[category]:\n",
    "            combined_df = pd.concat(category_dfs[category], ignore_index=True)\n",
    "            # Save to CSV\n",
    "            output_path = f'/Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/{category}.csv'\n",
    "            combined_df.to_csv(output_path, index=False)\n",
    "            print(f\"{category}: {len(combined_df)} rows saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the final dataset: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCVR transformation completed. Results saved to 'secured_code.csv'\n"
     ]
    }
   ],
   "source": [
    "# apply the TrustChain Verification Refactoring (TCVR) algorithm \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_interaction_details(code_snippet):\n",
    "    \"\"\"\n",
    "    Extract relevant details about external interactions from the code snippet.\n",
    "    \"\"\"\n",
    "    # Extract socket-related operations\n",
    "    socket_ops = {\n",
    "        'read': bool(re.search(r'getInputStream()', code_snippet)),\n",
    "        'write': bool(re.search(r'getOutputStream()', code_snippet)),\n",
    "        'connect': bool(re.search(r'socket\\.connect|new Socket', code_snippet))\n",
    "    }\n",
    "    return socket_ops\n",
    "\n",
    "def construct_verification(interaction_details):\n",
    "    \"\"\"\n",
    "    Construct appropriate verification mechanisms based on interaction details.\n",
    "    \"\"\"\n",
    "    verifications = []\n",
    "    \n",
    "    if interaction_details['connect']:\n",
    "        verifications.append(\"\"\"\n",
    "        // Verify server certificate and establish SSL connection\n",
    "        SSLContext sslContext = SSLContext.getInstance(\"TLS\");\n",
    "        sslContext.init(null, trustStore.getCustomTrustManagers(), new SecureRandom());\n",
    "        SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();\n",
    "        SSLSocket sslSocket = (SSLSocket) sslSocketFactory.createSocket(host, port);\n",
    "        \"\"\")\n",
    "    \n",
    "    if interaction_details['read']:\n",
    "        verifications.append(\"\"\"\n",
    "        // Verify data integrity before reading\n",
    "        if (!verifyMessageIntegrity(inputStream)) {\n",
    "            throw new SecurityException(\"Message integrity verification failed\");\n",
    "        }\n",
    "        \"\"\")\n",
    "    \n",
    "    if interaction_details['write']:\n",
    "        verifications.append(\"\"\"\n",
    "        // Sign outgoing data\n",
    "        signAndWriteData(outputStream, data);\n",
    "        \"\"\")\n",
    "    \n",
    "    return \"\\n\".join(verifications)\n",
    "\n",
    "def build_verified_execution(code_snippet):\n",
    "    \"\"\"\n",
    "    Build a secure version of the code with verification mechanisms.\n",
    "    \"\"\"\n",
    "    interaction_details = extract_interaction_details(code_snippet)\n",
    "    verifications = construct_verification(interaction_details)\n",
    "    \n",
    "    # Base security imports and configurations\n",
    "    secure_code = \"\"\"\n",
    "    import javax.net.ssl.*;\n",
    "    import java.security.*;\n",
    "    \n",
    "    // Initialize security components\n",
    "    private static final TrustManager[] trustStore = createTrustStore();\n",
    "    private static final KeyStore keyStore = loadKeyStore();\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace plain socket operations with secure versions\n",
    "    secure_code = secure_code.strip()\n",
    "    \n",
    "    if interaction_details['connect']:\n",
    "        code_snippet = re.sub(\n",
    "            r'new Socket\\((.*?)\\)',\n",
    "            r'sslSocketFactory.createSocket(\\1)',\n",
    "            code_snippet\n",
    "        )\n",
    "    \n",
    "    if interaction_details['read'] or interaction_details['write']:\n",
    "        code_snippet = re.sub(\n",
    "            r'socket\\.(getInputStream|getOutputStream)\\(\\)',\n",
    "            r'sslSocket.\\1()',\n",
    "            code_snippet\n",
    "        )\n",
    "    \n",
    "    # Add verification mechanisms\n",
    "    if verifications:\n",
    "        # Insert verifications before the socket operations\n",
    "        lines = code_snippet.split('\\n')\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'socket.' in line or 'new Socket' in line:\n",
    "                lines.insert(i, verifications)\n",
    "                break\n",
    "        code_snippet = '\\n'.join(lines)\n",
    "    \n",
    "    return secure_code + \"\\n\" + code_snippet\n",
    "\n",
    "def apply_tcvr(df):\n",
    "    \"\"\"\n",
    "    Apply TCVR algorithm to the entire dataset.\n",
    "    \"\"\"\n",
    "    # Create a new column for the secure code\n",
    "    df['code_fix'] = df['Code Snippet'].apply(build_verified_execution)\n",
    "    return df\n",
    "\n",
    "# Read the input CSV file\n",
    "df = pd.read_csv('/Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/ITV.csv')\n",
    "\n",
    "# Apply TCVR\n",
    "df_secured = apply_tcvr(df)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "df_secured.to_csv('ITV_with_fixes.csv', index=False)\n",
    "\n",
    "print(\"TCVR transformation completed. Results saved to 'secured_code.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed the code snippets.\n",
      "Total rows processed: 5000\n",
      "Results saved to 'processed_code_with_fixes.csv'\n"
     ]
    }
   ],
   "source": [
    "# apply Output Safety Refactoring (OSR)\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class OSRRefactorer:\n",
    "    def __init__(self):\n",
    "        self.sanitization_patterns = {\n",
    "            'command_injection': {\n",
    "                'pattern': r'ProcessExecutor\\.getInstance\\((.*?)\\)',\n",
    "                'fixes': {\n",
    "                    'LIBRE_OFFICE': self._fix_libre_office_command,\n",
    "                    'OCR_MY_PDF': self._fix_ocr_command,\n",
    "                    'PYTHON_OPENCV': self._fix_opencv_command,\n",
    "                    'CALIBRE': self._fix_calibre_command,\n",
    "                    'GHOSTSCRIPT': self._fix_ghostscript_command\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _fix_libre_office_command(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply security fixes for LibreOffice command execution\n",
    "        \"\"\"\n",
    "        security_wrapper = \"\"\"\n",
    "        // Create a secure command executor\n",
    "        class SecureCommandExecutor {\n",
    "            private final ProcessExecutor executor;\n",
    "            private final CommandValidator validator;\n",
    "            \n",
    "            public SecureCommandExecutor() {\n",
    "                this.executor = ProcessExecutor.getInstance(ProcessExecutor.Processes.LIBRE_OFFICE);\n",
    "                this.validator = new CommandValidator();\n",
    "            }\n",
    "            \n",
    "            public ProcessExecutorResult execute(List<String> command) throws SecurityException {\n",
    "                // Validate and sanitize each command component\n",
    "                List<String> sanitizedCommand = new ArrayList<>();\n",
    "                for (String component : command) {\n",
    "                    String sanitized = validator.sanitizeInput(component);\n",
    "                    validator.validateComponent(sanitized);\n",
    "                    sanitizedCommand.add(sanitized);\n",
    "                }\n",
    "                \n",
    "                // Execute in restricted environment\n",
    "                return executor.runCommandWithRestrictions(sanitizedCommand);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Use the secure executor\n",
    "        SecureCommandExecutor executor = new SecureCommandExecutor();\n",
    "        return executor.execute(command);\n",
    "        \"\"\"\n",
    "        \n",
    "        return re.sub(\n",
    "            r'ProcessExecutor\\.getInstance\\(ProcessExecutor\\.Processes\\.LIBRE_OFFICE\\).*?command\\)',\n",
    "            security_wrapper,\n",
    "            code,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "\n",
    "    def _fix_ocr_command(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply security fixes for OCR command execution\n",
    "        \"\"\"\n",
    "        security_wrapper = \"\"\"\n",
    "        // Create secure OCR command builder\n",
    "        class SecureOCRCommandBuilder {\n",
    "            private final List<String> command = new ArrayList<>();\n",
    "            private final PathValidator pathValidator = new PathValidator();\n",
    "            \n",
    "            public List<String> buildCommand(Path input, Path output, OCROptions options) {\n",
    "                // Validate paths\n",
    "                pathValidator.validatePath(input);\n",
    "                pathValidator.validatePath(output);\n",
    "                \n",
    "                // Build command with sanitized inputs\n",
    "                command.add(\"ocrmypdf\");\n",
    "                command.add(\"--verbose\");\n",
    "                command.add(sanitizeArg(options.getVerbosity()));\n",
    "                \n",
    "                // Add sanitized options\n",
    "                if (options.hasSidecar()) {\n",
    "                    command.add(\"--sidecar\");\n",
    "                    command.add(pathValidator.sanitizePath(options.getSidecarPath()));\n",
    "                }\n",
    "                \n",
    "                return Collections.unmodifiableList(command);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Use secure builder\n",
    "        SecureOCRCommandBuilder builder = new SecureOCRCommandBuilder();\n",
    "        List<String> sanitizedCommand = builder.buildCommand(inputPath, outputPath, options);\n",
    "        return ProcessExecutor.getInstance(ProcessExecutor.Processes.OCR_MY_PDF)\n",
    "                            .runCommandWithSecurityContext(sanitizedCommand);\n",
    "        \"\"\"\n",
    "        \n",
    "        return re.sub(\n",
    "            r'ProcessExecutor\\.getInstance\\(ProcessExecutor\\.Processes\\.OCR_MY_PDF\\).*?command\\)',\n",
    "            security_wrapper,\n",
    "            code,\n",
    "            flags=re.DOTALL\n",
    "        )\n",
    "\n",
    "    def _fix_opencv_command(self, code: str) -> str:\n",
    "        \"\"\"Similar pattern for OpenCV commands\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _fix_calibre_command(self, code: str) -> str:\n",
    "        \"\"\"Similar pattern for Calibre commands\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _fix_ghostscript_command(self, code: str) -> str:\n",
    "        \"\"\"Similar pattern for Ghostscript commands\"\"\"\n",
    "        pass\n",
    "\n",
    "    def apply_osr(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        Apply Output Safety Refactoring to the given code\n",
    "        \"\"\"\n",
    "        # Create base security context\n",
    "        security_context = \"\"\"\n",
    "        // Add security context\n",
    "        class SecurityContext {\n",
    "            private final Map<String, String> restrictedEnv;\n",
    "            private final Set<String> allowedCommands;\n",
    "            \n",
    "            public SecurityContext() {\n",
    "                this.restrictedEnv = new HashMap<>();\n",
    "                this.allowedCommands = new HashSet<>();\n",
    "                initializeSecurityContext();\n",
    "            }\n",
    "            \n",
    "            private void initializeSecurityContext() {\n",
    "                // Set minimal environment\n",
    "                restrictedEnv.put(\"PATH\", System.getenv(\"PATH\"));\n",
    "                // Add allowed commands\n",
    "                allowedCommands.addAll(Arrays.asList(\"unoconv\", \"ocrmypdf\", \"python\"));\n",
    "            }\n",
    "            \n",
    "            public boolean validateCommand(List<String> command) {\n",
    "                return command.stream()\n",
    "                    .allMatch(this::isAllowedCommand);\n",
    "            }\n",
    "            \n",
    "            private boolean isAllowedCommand(String cmd) {\n",
    "                return allowedCommands.contains(cmd) ||\n",
    "                       cmd.startsWith(\"--\") || // Allow flags\n",
    "                       cmd.matches(\"^[a-zA-Z0-9/_.-]+$\"); // Allow safe paths\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add input validation\n",
    "        input_validation = \"\"\"\n",
    "        class InputValidator {\n",
    "            public static void validateInput(String input) {\n",
    "                if (input == null || input.isEmpty()) {\n",
    "                    throw new IllegalArgumentException(\"Input cannot be null or empty\");\n",
    "                }\n",
    "                if (input.contains(\"..\")) {\n",
    "                    throw new SecurityException(\"Path traversal attempt detected\");\n",
    "                }\n",
    "                // Add more validation as needed\n",
    "            }\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        # Apply security fixes based on patterns\n",
    "        modified_code = code\n",
    "        for pattern_type, pattern_info in self.sanitization_patterns.items():\n",
    "            matches = re.finditer(pattern_info['pattern'], code)\n",
    "            for match in matches:\n",
    "                process_type = match.group(1).strip()\n",
    "                if process_type in pattern_info['fixes']:\n",
    "                    modified_code = pattern_info['fixes'][process_type](modified_code)\n",
    "        \n",
    "        # Add security context and validation\n",
    "        modified_code = security_context + input_validation + modified_code\n",
    "        \n",
    "        return modified_code\n",
    "\n",
    "def process_csv(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the CSV file and apply OSR to the Code Snippet column\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Initialize the OSR refactorer\n",
    "    refactorer = OSRRefactorer()\n",
    "    \n",
    "    # Create a new column for fixed code\n",
    "    df['code_fix'] = df['Code Snippet'].apply(lambda x: refactorer.apply_osr(x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # File path from the provided dataset\n",
    "    file_path = \"/Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/LOIS.csv\"\n",
    "    \n",
    "    # Process the CSV and apply OSR\n",
    "    try:\n",
    "        result_df = process_csv(file_path)\n",
    "        print(\"Successfully processed the code snippets.\")\n",
    "        print(f\"Total rows processed: {len(result_df)}\")\n",
    "        \n",
    "        # Optionally save the results\n",
    "        result_df.to_csv(\"LOIS_fixes.csv\", index=False)\n",
    "        print(\"Results saved to 'processed_code_with_fixes.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply WVR algorithm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_input_data(code):\n",
    "    \"\"\"Enhanced input data extraction with more comprehensive patterns.\"\"\"\n",
    "    input_patterns = [\n",
    "        # HTTP Parameters and Annotations\n",
    "        r'@PathParam\\(\"([^\"]+)\"\\)',\n",
    "        r'@QueryParam\\(\"([^\"]+)\"\\)',\n",
    "        r'@FormParam\\(\"([^\"]+)\"\\)',\n",
    "        r'@RequestParam\\(\"([^\"]+)\"\\)',\n",
    "        r'@ModelAttribute\\s+\\w+\\s+(\\w+)',\n",
    "        r'getParameter\\(\"([^\"]+)\"\\)',\n",
    "        \n",
    "        # Message and Resource Handling\n",
    "        r'getMessage\\(([^,)]+)',\n",
    "        r'ResourceBundle\\.getBundle\\(\"([^\"]+)\"',\n",
    "        r'format\\(\"([^\"]+)\"',\n",
    "        r'String\\.format\\(\"([^\"]+)\"',\n",
    "        r'MessageFormat\\.format\\(\"([^\"]+)\"',\n",
    "        \n",
    "        # Variable Declarations and Assignments\n",
    "        r'String\\s+(\\w+)\\s*=',\n",
    "        r'(\\w+)\\s*=\\s*[^=]+getParameter',\n",
    "        r'(\\w+)\\s*=\\s*[^=]+getMessage',\n",
    "        r'(\\w+)\\s*=\\s*[^=]+format',\n",
    "        \n",
    "        # Method Parameters\n",
    "        r'public\\s+[\\w<>[\\],\\s]+\\s+\\w+\\(([^)]+)\\)',\n",
    "        r'private\\s+[\\w<>[\\],\\s]+\\s+\\w+\\(([^)]+)\\)',\n",
    "        r'protected\\s+[\\w<>[\\],\\s]+\\s+\\w+\\(([^)]+)\\)',\n",
    "        \n",
    "        # Additional Format String Patterns\n",
    "        r'\\.format\\(([^)]+)\\)',\n",
    "        r'\\.printf\\(([^)]+)\\)',\n",
    "        r'PrintStream\\.printf\\(([^)]+)\\)',\n",
    "        r'Formatter\\.format\\(([^)]+)\\)',\n",
    "        \n",
    "        # Logger and Error Messages\n",
    "        r'logger\\.(error|warn|info|debug)\\(([^)]+)\\)',\n",
    "        r'LOG\\.(error|warn|info|debug)\\(([^)]+)\\)',\n",
    "        r'throw new \\w+Exception\\(([^)]+)\\)',\n",
    "        \n",
    "        # Resource and File Operations\n",
    "        r'new File\\(\"([^\"]+)\"\\)',\n",
    "        r'Paths\\.get\\(\"([^\"]+)\"\\)',\n",
    "        r'createTempFile\\(\"([^\"]+)\"',\n",
    "        r'FileInputStream\\(\"([^\"]+)\"\\)',\n",
    "        r'FileOutputStream\\(\"([^\"]+)\"\\)',\n",
    "        \n",
    "        # Additional Input Sources\n",
    "        r'request\\.getAttribute\\(\"([^\"]+)\"\\)',\n",
    "        r'session\\.getAttribute\\(\"([^\"]+)\"\\)',\n",
    "        r'cookie\\.getValue\\(\"([^\"]+)\"\\)',\n",
    "        r'headers\\.get\\(\"([^\"]+)\"\\)'\n",
    "    ]\n",
    "    \n",
    "    inputs = set()\n",
    "    for pattern in input_patterns:\n",
    "        try:\n",
    "            matches = re.finditer(pattern, code)\n",
    "            for match in matches:\n",
    "                # Extract all capturing groups\n",
    "                groups = match.groups()\n",
    "                for group in groups:\n",
    "                    if group and isinstance(group, str):\n",
    "                        # Clean and validate the input\n",
    "                        cleaned = group.strip().strip('\"\\'')\n",
    "                        if cleaned and not cleaned.startswith('{'): \n",
    "                            inputs.add(cleaned)\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    # Extract method parameters\n",
    "    try:\n",
    "        method_params = re.findall(r'(\\w+)\\s+(\\w+)(?=\\s*[,)])', code)\n",
    "        inputs.update(param[1] for param in method_params)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return list(inputs)\n",
    "\n",
    "def determine_whitelist_pattern(input_data):\n",
    "    \"\"\"Enhanced whitelist pattern determination with more specific patterns.\"\"\"\n",
    "    patterns = {\n",
    "        # File System Patterns\n",
    "        'file': r'^[\\w\\-. /\\\\]+$',\n",
    "        'path': r'^[\\w\\-. /\\\\]+$',\n",
    "        'dir': r'^[\\w\\-. /\\\\]+$',\n",
    "        'temp': r'^[\\w\\-. ]+$',\n",
    "        \n",
    "        # Web and URL Patterns\n",
    "        'url': r'^[a-zA-Z0-9\\-._~:/?#\\[\\]@!$&\\'()*+,;=\\s]+$',\n",
    "        'uri': r'^[a-zA-Z0-9\\-._~:/?#\\[\\]@!$&\\'()*+,;=\\s]+$',\n",
    "        'http': r'^https?://[\\w\\-._~:/?#\\[\\]@!$&\\'()*+,;=\\s]+$',\n",
    "        \n",
    "        # Identity and Authentication\n",
    "        'realm': r'^[\\w\\-]+$',\n",
    "        'user': r'^[\\w\\-@.]+$',\n",
    "        'email': r'^[\\w\\-\\.]+@([\\w\\-]+\\.)+[\\w\\-]{2,4}$',\n",
    "        'password': r'^[\\S]+$',\n",
    "        'token': r'^[\\w\\-]+$',\n",
    "        \n",
    "        # Format and Content Type\n",
    "        'format': r'^[\\w\\-/+.]+$',\n",
    "        'type': r'^[\\w\\-/+.]+$',\n",
    "        'content': r'^[\\w\\-/+.]+$',\n",
    "        'mime': r'^[\\w\\-/+.]+$',\n",
    "        \n",
    "        # Message and Locale\n",
    "        'bundle': r'^[\\w._]+$',\n",
    "        'locale': r'^[a-z]{2}(-[A-Z]{2})?$',\n",
    "        'message': r'^[\\w\\-._{}\\s]+$',\n",
    "        'error': r'^[\\w\\-._{}\\s]+$',\n",
    "        'log': r'^[\\w\\-._{}\\s]+$',\n",
    "        \n",
    "        # Database and Query\n",
    "        'id': r'^\\d+$',\n",
    "        'query': r'^[\\w\\s\\-=><&|()]+$',\n",
    "        'key': r'^[\\w\\-]+$',\n",
    "        \n",
    "        # Numbers and Dates\n",
    "        'number': r'^\\d+$',\n",
    "        'date': r'^\\d{4}-\\d{2}-\\d{2}$',\n",
    "        'time': r'^\\d{2}:\\d{2}:\\d{2}$',\n",
    "        'timestamp': r'^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(.\\d{3})?Z?$',\n",
    "        \n",
    "        # Default Pattern\n",
    "        'default': r'^[\\w\\-._\\s]+$'\n",
    "    }\n",
    "    \n",
    "    input_lower = input_data.lower()\n",
    "    \n",
    "    # Context-based pattern matching\n",
    "    if re.search(r'file|path|directory', input_lower):\n",
    "        return patterns['file']\n",
    "    elif re.search(r'url|uri|http', input_lower):\n",
    "        return patterns['url']\n",
    "    elif re.search(r'date|time|timestamp', input_lower):\n",
    "        return patterns['timestamp']\n",
    "    elif re.search(r'id|key|index', input_lower):\n",
    "        return patterns['id']\n",
    "    elif re.search(r'message|error|log', input_lower):\n",
    "        return patterns['message']\n",
    "    elif re.search(r'format|type|mime', input_lower):\n",
    "        return patterns['format']\n",
    "    \n",
    "    # Use default pattern if no specific match found\n",
    "    return patterns['default']\n",
    "\n",
    "def build_validation(input_data, pattern):\n",
    "    \"\"\"Build comprehensive validation with additional security checks.\"\"\"\n",
    "    return f\"\"\"\n",
    "    // Input validation for {input_data}\n",
    "    if ({input_data} != null) {{\n",
    "        // Length check\n",
    "        if ({input_data}.length() > 1000) {{\n",
    "            throw new IllegalArgumentException(\"{input_data} exceeds maximum length\");\n",
    "        }}\n",
    "        // Pattern validation\n",
    "        if (!Pattern.matches(\"{pattern}\", {input_data})) {{\n",
    "            throw new IllegalArgumentException(\"Invalid format for {input_data}\");\n",
    "        }}\n",
    "        // Sanitize input\n",
    "        {input_data} = {input_data}\n",
    "            .trim()\n",
    "            .replaceAll(\"[\\\\r\\\\n]\", \"\")\n",
    "            .replaceAll(\"[\\\\x00-\\\\x1F\\\\x7F]\", \"\");\n",
    "            \n",
    "        // Additional security check for file paths\n",
    "        if ({input_data}.contains(\"..\")) {{\n",
    "            throw new IllegalArgumentException(\"Path traversal attempt detected\");\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "def build_input_handling(validation, original_code):\n",
    "    \"\"\"Enhanced input handling with better code structure preservation.\"\"\"\n",
    "    try:\n",
    "        lines = original_code.split('\\n')\n",
    "        modified_lines = []\n",
    "        validation_added = False\n",
    "        \n",
    "        # Common vulnerability patterns\n",
    "        vuln_patterns = [\n",
    "            'getMessage', 'ResourceBundle.getBundle', '@PathParam',\n",
    "            'getParameter', 'format', 'new File', 'Paths.get',\n",
    "            'createTempFile', 'FileInputStream', 'FileOutputStream',\n",
    "            'getAttribute', 'getValue', 'headers.get'\n",
    "        ]\n",
    "        \n",
    "        # Method declaration pattern\n",
    "        method_pattern = re.compile(r'(public|private|protected)\\s+[\\w<>[\\],\\s]+\\s+\\w+\\s*\\(')\n",
    "        \n",
    "        inside_method = False\n",
    "        for line in lines:\n",
    "            # Check if we're entering a method\n",
    "            if method_pattern.search(line):\n",
    "                inside_method = True\n",
    "                modified_lines.append(line)\n",
    "                if not validation_added:\n",
    "                    modified_lines.append(validation)\n",
    "                    validation_added = True\n",
    "                continue\n",
    "            \n",
    "            # Add validation before vulnerable lines\n",
    "            if inside_method and not validation_added:\n",
    "                if any(pattern in line for pattern in vuln_patterns):\n",
    "                    modified_lines.append(validation)\n",
    "                    validation_added = True\n",
    "            \n",
    "            modified_lines.append(line)\n",
    "        \n",
    "        return '\\n'.join(modified_lines)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in build_input_handling: {str(e)}\")\n",
    "        return original_code\n",
    "\n",
    "def apply_wvr(code_snippet):\n",
    "    \"\"\"Apply enhanced WVR with better error handling and logging.\"\"\"\n",
    "    if not isinstance(code_snippet, str) or not code_snippet.strip():\n",
    "        return code_snippet\n",
    "    \n",
    "    try:\n",
    "        # Extract all potential input points\n",
    "        inputs = extract_input_data(code_snippet)\n",
    "        \n",
    "        if not inputs:\n",
    "            return code_snippet\n",
    "        \n",
    "        # Apply WVR for each input\n",
    "        modified_code = code_snippet\n",
    "        for input_data in inputs:\n",
    "            pattern = determine_whitelist_pattern(input_data)\n",
    "            validation = build_validation(input_data, pattern)\n",
    "            modified_code = build_input_handling(validation, modified_code)\n",
    "        \n",
    "        return modified_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing code snippet: {str(e)}\")\n",
    "        return code_snippet\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv('/Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/DataSet/LOWV.csv')\n",
    "        print(f\"Total rows in dataset: {len(df)}\")\n",
    "        \n",
    "        # Apply WVR to each code snippet\n",
    "        df['code_fix'] = df['Code Snippet'].apply(apply_wvr)        \n",
    "        # Save the results\n",
    "        df.to_csv('LOWV_results.csv', index=False)\n",
    "        print(\"WVR processing completed. Results saved to 'wvr_results.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main processing: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been combined into 'dataSet_withFixes.csv'\n",
      "Total number of rows in the combined dataframe: 10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = '/Users/obiedaananbeh/Desktop/Repo/VulDediction/Apply refactoring technique/fix_Code'\n",
    "\n",
    "# List to hold dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_df.to_csv('/Users/obiedaananbeh/Desktop/Repo/VulDediction/DataSet/dataSet_withFixes.csv', index=False)\n",
    "\n",
    "print(\"All CSV files have been combined into 'dataSet_withFixes.csv'\")\n",
    "\n",
    "# Print the total number of rows in the combined dataframe\n",
    "total_rows = len(combined_df)\n",
    "print(f\"Total number of rows in the combined dataframe: {total_rows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
